{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f425de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650b728",
   "metadata": {},
   "source": [
    "# Import squat example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0a1281eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/home/garbade/libs/aisc/action-recognition/demos/skeletons_as_numpy.npy\"\n",
    "filename_neg = \"/home/garbade/libs/aisc/action-recognition/demos/skeletons_as_numpy_negative.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8dab0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(filename)\n",
    "data_neg = np.load(filename_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef1bd19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 17, 3)\n",
      "(33874, 17, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data_neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b79897",
   "metadata": {},
   "source": [
    "## Add neck joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4ef40cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "native_keypoint_names: [\n",
    "            \"Nose\",\n",
    "            \"RightShoulder\",\n",
    "            \"RightElbow\",\n",
    "            \"RightWrist\",\n",
    "            \"LeftShoulder\",\n",
    "            \"LeftElbow\",\n",
    "            \"LeftWrist\",\n",
    "            \"RightHip\",\n",
    "            \"RightKnee\",\n",
    "            \"RightAnkle\",\n",
    "            \"LeftHip\",\n",
    "            \"LeftKnee\",\n",
    "            \"LeftAnkle\",\n",
    "            \"RightEye\",\n",
    "            \"LeftEye\",\n",
    "            \"RightEar\",\n",
    "            \"LeftEar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca219f",
   "metadata": {},
   "source": [
    "neck keypoint is missing -> should come second after \"Nose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6f50d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neck_to_keypoints(skeletons):\n",
    "    new_skeletons = []\n",
    "    for skeleton_frame in skeletons:\n",
    "        nose = skeleton_frame[:1,:]\n",
    "        neck = (skeleton_frame[1,:] + skeleton_frame[4,:]) / 2.0\n",
    "        rest = skeleton_frame[1:,:]\n",
    "        pose_concat = np.concatenate((nose, np.expand_dims(neck, 0), rest), axis=0)\n",
    "        new_skeletons.append(pose_concat)\n",
    "    return np.array(new_skeletons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6083b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c0916634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neck.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1d63065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "8c56d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletons_corr = add_neck_to_keypoints(data)\n",
    "skeletons_corr_neg = add_neck_to_keypoints(data_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b3a526f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 18, 3)\n",
      "(33874, 18, 3)\n"
     ]
    }
   ],
   "source": [
    "print(skeletons_corr.shape)\n",
    "print(skeletons_corr_neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbeff23",
   "metadata": {},
   "source": [
    "# Create single NN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8f9c85ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_nn_input = skeletons_corr[:79,:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "72bdcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 18, 2)\n"
     ]
    }
   ],
   "source": [
    "print(single_nn_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8180386",
   "metadata": {},
   "source": [
    "# Load tflite AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2038601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"/media/data_ssd/libs/mediapipe_v0.8.9/mediapipe/models/model_ar_v18s_01_mediapipe_tflite.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=model_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "931240d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'input_2', 'index': 0, 'shape': array([ 1, 79, 18,  2], dtype=int32), 'shape_signature': array([ 1, 79, 18,  2], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "[{'name': 'Identity', 'index': 192, 'shape': array([ 1, 23], dtype=int32), 'shape_signature': array([ 1, 23], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "print(input_details)\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1fd21",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ee86b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"skeletons_with_neck_squat_79x18x2.npy\", skeletons_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b66ba183",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = single_nn_input\n",
    "\n",
    "input_tensor = np.expand_dims(input_data.astype(np.float32), axis=0)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "output_data = np.squeeze(output_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "930a411b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.3521575e+01, -2.4610739e+01, -2.1907761e+01, -1.8666994e+01,\n",
       "       -1.3113013e-06, -2.0498335e+01, -2.2552057e+01, -2.0804609e+01,\n",
       "       -2.5740786e+01, -2.5391951e+01, -2.0525833e+01, -2.2698870e+01,\n",
       "       -2.4558897e+01, -2.0615149e+01, -2.3449255e+01, -1.8619581e+01,\n",
       "       -1.9773645e+01, -2.2957602e+01, -1.8723085e+01, -1.7083897e+01,\n",
       "       -2.3289736e+01, -2.1011726e+01, -2.7642921e+01], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93054b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a9b141b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1617855c",
   "metadata": {},
   "source": [
    "# Get action class corresponding to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77ce2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_classes = [\n",
    "        \"background\",\n",
    "        \"box\",\n",
    "        \"clap\",\n",
    "        \"jump\",\n",
    "        \"squat\",\n",
    "        \"wave\",\n",
    "        \"rotate\",\n",
    "        \"climb\",\n",
    "        \"run_on_spot\",\n",
    "        \"rope_jump\",\n",
    "        \"fly-like-bird\",\n",
    "        \"jumping-jack\",\n",
    "        \"holahoop\",\n",
    "        \"look-out\",\n",
    "        \"eat-something\",\n",
    "        \"jump-like-frog\",\n",
    "        \"bang-with-hammer\",\n",
    "        \"boxes-from-left-to-right\",\n",
    "        \"cook\",\n",
    "        \"horse-petting\",\n",
    "        \"throw-stone\",\n",
    "        \"pull-rope\",\n",
    "        \"lift-bucket-from-floor\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a52ec951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: squat\n"
     ]
    }
   ],
   "source": [
    "action_id = output_data.argmax(axis=0)\n",
    "\n",
    "print(\"predicted class: \" + action_classes[action_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8c8ceb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: -1.3113013e-06\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \" + str(output_data[action_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca0bb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fabd54e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34169704e-06, 2.04970936e-11, 3.05900888e-10, 7.81677745e-09,\n",
       "       9.99998689e-01, 1.25223698e-09, 1.60607652e-10, 9.21877519e-10,\n",
       "       6.62093167e-12, 9.38461028e-12, 1.21827193e-09, 1.38677625e-10,\n",
       "       2.15877212e-11, 1.11417908e-09, 6.54814397e-11, 8.19631918e-09,\n",
       "       2.58472999e-09, 1.07063296e-10, 7.39039363e-09, 3.80678387e-08,\n",
       "       7.68062350e-11, 7.49416751e-10, 9.88170808e-13], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5851967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax score: 0.9999987\n"
     ]
    }
   ],
   "source": [
    "print(\"softmax score: \" + str(softmax(output_data)[action_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc358a28",
   "metadata": {},
   "source": [
    "# Write example input to C++ readable file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b4766af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e21d4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_2D = input_data.reshape((79,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "273c6773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103.84735 , 151.06212 ],\n",
       "       [ 97.68504 , 168.07446 ],\n",
       "       [ 81.665085, 168.16046 ],\n",
       "       [ 68.523674, 188.66692 ],\n",
       "       [ 74.398506, 201.2924  ],\n",
       "       [113.704994, 167.98846 ],\n",
       "       [123.47378 , 186.26178 ],\n",
       "       [133.21793 , 200.10634 ],\n",
       "       [ 84.70395 , 220.2473  ],\n",
       "       [ 86.980034, 255.46948 ],\n",
       "       [ 85.59968 , 294.20245 ],\n",
       "       [105.12618 , 221.32732 ],\n",
       "       [106.3571  , 257.34686 ],\n",
       "       [104.31472 , 292.23346 ],\n",
       "       [100.299774, 147.1401  ],\n",
       "       [105.78834 , 147.37265 ],\n",
       "       [ 94.929276, 148.57346 ],\n",
       "       [105.97988 , 148.91405 ]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5623a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103.84735 , 151.06212 ,  97.68504 , 168.07446 ,  81.665085,\n",
       "       168.16046 ,  68.523674, 188.66692 ,  74.398506, 201.2924  ,\n",
       "       113.704994, 167.98846 , 123.47378 , 186.26178 , 133.21793 ,\n",
       "       200.10634 ,  84.70395 , 220.2473  ,  86.980034, 255.46948 ,\n",
       "        85.59968 , 294.20245 , 105.12618 , 221.32732 , 106.3571  ,\n",
       "       257.34686 , 104.31472 , 292.23346 , 100.299774, 147.1401  ,\n",
       "       105.78834 , 147.37265 ,  94.929276, 148.57346 , 105.97988 ,\n",
       "       148.91405 ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data_2D[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fca3dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"skeletons_with_neck_squat_79x36.mat\", input_data_2D, delimiter=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9fb96b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols, nchannels = input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5aecb7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(nrows):\n",
    "    for channel in range(nchannels):\n",
    "        for col in range(ncols):\n",
    "            input_data[row, col, channel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d2c1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_matrix3D_to_ascii(filename, matrix3D):\n",
    "    \n",
    "    nrows, ncols, nchannels = input_data.shape\n",
    "    \n",
    "    with open(filename, \"w\") as file:\n",
    "        \n",
    "        # write header [rows x cols x channels]\n",
    "        nrows, ncols, nchannels = matrix3D.shape\n",
    "        file.write(f\"{nrows} {ncols} {nchannels}\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        # write values \n",
    "        for row in range(nrows):\n",
    "            for channel in range(nchannels):\n",
    "                for col in range(ncols):\n",
    "                    value = matrix3D[row, col, channel]\n",
    "                    \n",
    "                    file.write(str(value))\n",
    "                    file.write(\" \")\n",
    "            file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf16da9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_matrix2D_to_ascii(filename, matrix2D):\n",
    "    \n",
    "    nrows, ncols = matrix2D.shape\n",
    "    \n",
    "    with open(filename, \"w\") as file:\n",
    "        \n",
    "        # write header [rows x cols]\n",
    "        nrows, ncols = matrix2D.shape\n",
    "        file.write(f\"{nrows} {ncols}\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        # write values \n",
    "        for row in range(nrows):\n",
    "            for col in range(ncols):\n",
    "                value = matrix2D[row, col]\n",
    "\n",
    "                file.write(str(value))\n",
    "                file.write(\" \")\n",
    "            file.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e735b70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.84735\n",
      "97.68504\n",
      "81.665085\n",
      "68.523674\n",
      "74.398506\n",
      "113.704994\n",
      "123.47378\n",
      "133.21793\n",
      "84.70395\n",
      "86.980034\n",
      "85.59968\n",
      "105.12618\n",
      "106.3571\n",
      "104.31472\n",
      "100.299774\n",
      "105.78834\n",
      "94.929276\n",
      "105.97988\n",
      "151.06212\n",
      "168.07446\n",
      "168.16046\n",
      "188.66692\n",
      "201.2924\n",
      "167.98846\n",
      "186.26178\n",
      "200.10634\n",
      "220.2473\n",
      "255.46948\n",
      "294.20245\n",
      "221.32732\n",
      "257.34686\n",
      "292.23346\n",
      "147.1401\n",
      "147.37265\n",
      "148.57346\n",
      "148.91405\n"
     ]
    }
   ],
   "source": [
    "for channel in range(nchannels):\n",
    "    for col in range(ncols):\n",
    "        print(input_data[0, col, channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8cb9fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "1\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(row)\n",
    "print(channel)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "433dd0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 2)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "92e5d116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5775c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_matrix3D_to_ascii(\"skeletons_with_neck_squat_79x18x2.mat\", input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c3cc34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_matrix2D_to_ascii(\"skeletons_with_neck_squat_79x36.mat\", input_data_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0eb854cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/data_ssd/libs/mediapipe_v0.8.9/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d6dcb",
   "metadata": {},
   "source": [
    "# Compute class for C++ output prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fed593da",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cpp = np.array([\n",
    "-0.414527, \n",
    "-3.72665, \n",
    "-6.21815, \n",
    "-6.29307, \n",
    "-4.09375, \n",
    "-4.19713, \n",
    "-6.88958, \n",
    "-6.72822, \n",
    "-6.16086, \n",
    "-7.08454, \n",
    "-8.50217, \n",
    "-8.53692, \n",
    "-9.018, \n",
    "-4.46563, \n",
    "-6.14306, \n",
    "-2.60321, \n",
    "-3.2298, \n",
    "-2.87857, \n",
    "-7.73492, \n",
    "-7.26222, \n",
    "-6.36653, \n",
    "-5.81333, \n",
    "-2.46831, \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0025024e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.60651899e-01, 2.40733176e-02, 1.99292632e-03, 1.84907234e-03,\n",
       "       1.66765589e-02, 1.50386578e-02, 1.01834023e-03, 1.19665968e-03,\n",
       "       2.11043497e-03, 8.37959150e-04, 2.03027076e-04, 1.96093062e-04,\n",
       "       1.21208154e-04, 1.14974362e-02, 2.14833704e-03, 7.40354530e-02,\n",
       "       3.95653634e-02, 5.62150252e-02, 4.37286835e-04, 7.01548021e-04,\n",
       "       1.71810867e-03, 2.98746163e-03, 8.47278261e-02])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(predictions_cpp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b80bb879",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_id = softmax(predictions_cpp).argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e52ae682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: background\n"
     ]
    }
   ],
   "source": [
    "print(\"predicted class: \" + action_classes[action_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc153b",
   "metadata": {},
   "source": [
    "# Create train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7967e099",
   "metadata": {},
   "source": [
    "Params:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "715ab5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frames_per_sample = 79\n",
    "frames_per_sample = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "dd95c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 18, 3)\n",
      "(33874, 18, 3)\n"
     ]
    }
   ],
   "source": [
    "print(skeletons_corr.shape)\n",
    "print(skeletons_corr_neg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686691d",
   "metadata": {},
   "source": [
    "remove third dimension (score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "13c9409f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = skeletons_corr[:,:,:2]\n",
    "train_neg = skeletons_corr_neg[:,:,:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63f2d5c",
   "metadata": {},
   "source": [
    "combine last two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "96793d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos = train_pos.reshape(train_pos.shape[0], -1)\n",
    "train_neg = train_neg.reshape(train_neg.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "9366380f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 36)\n",
      "(33874, 36)\n"
     ]
    }
   ],
   "source": [
    "print(train_pos.shape)\n",
    "print(train_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "00df63bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_samples(skeletons, frames_per_sample):\n",
    "    pos_samples = []\n",
    "    for i in range(skeletons.shape[0] - frames_per_sample):\n",
    "        pos_samples.append(skeletons[i: i + frames_per_sample, :])\n",
    "\n",
    "    return np.array(pos_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "93b82eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_pos = create_multiple_samples(train_pos, frames_per_sample=frames_per_sample)\n",
    "data_train_neg = create_multiple_samples(train_neg, frames_per_sample=frames_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "60683fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 10, 36)\n",
      "(33864, 10, 36)\n"
     ]
    }
   ],
   "source": [
    "print(data_train_pos.shape)\n",
    "print(data_train_neg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "476bc310",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((data_train_pos, data_train_neg), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "1f4918b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34884, 10, 36)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "b6be2f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.zeros_like(np.squeeze(data_train_pos[:,0,0]))\n",
    "y_neg = np.ones_like(np.squeeze(data_train_neg[:,0,0]))\n",
    "y_train = np.concatenate((y_pos, y_neg), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "58f33654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "6e63f19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34884,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b3a9dc",
   "metadata": {},
   "source": [
    "# Train simple AR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bae11e",
   "metadata": {},
   "source": [
    "simple dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "4a105417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=(frames_per_sample, 36)),\n",
    "#     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(2)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "252e9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326f6dc",
   "metadata": {},
   "source": [
    "conv 1d model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "f69b9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv1D(filters=32, kernel_size=3, padding=\"valid\"),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "#     tf.keras.layers.Dense(2)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "e1ed51c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#              loss=loss_fn,\n",
    "#              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122fc93",
   "metadata": {},
   "source": [
    "conv 1d model - second try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "a849c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "b50178fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features = (frames_per_sample, 36)\n",
    "n_outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "ad05d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='sigmoid'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "28470600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34884, 1)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(y_train, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c500b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_41 (Conv1D)           (None, 8, 64)             6976      \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 6, 64)             12352     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 6, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               19300     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 38,830\n",
      "Trainable params: 38,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "56e02234",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 300.,\n",
    "                1: 1.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fa9bea7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1163/1163 [==============================] - 1s 1ms/step - loss: 9.3948 - accuracy: 0.0632\n",
      "Epoch 2/15\n",
      "1163/1163 [==============================] - 1s 962us/step - loss: 3.1387 - accuracy: 0.0396\n",
      "Epoch 3/15\n",
      "1163/1163 [==============================] - 1s 945us/step - loss: 3.1380 - accuracy: 0.0399\n",
      "Epoch 4/15\n",
      "1163/1163 [==============================] - 1s 977us/step - loss: 3.1376 - accuracy: 0.0399\n",
      "Epoch 5/15\n",
      "1163/1163 [==============================] - 1s 944us/step - loss: 3.1362 - accuracy: 0.0401\n",
      "Epoch 6/15\n",
      "1163/1163 [==============================] - 1s 945us/step - loss: 3.1367 - accuracy: 0.0402\n",
      "Epoch 7/15\n",
      "1163/1163 [==============================] - 1s 946us/step - loss: 3.1363 - accuracy: 0.0402\n",
      "Epoch 8/15\n",
      "1163/1163 [==============================] - 1s 954us/step - loss: 3.1358 - accuracy: 0.0403\n",
      "Epoch 9/15\n",
      "1163/1163 [==============================] - 1s 949us/step - loss: 3.1369 - accuracy: 0.0401\n",
      "Epoch 10/15\n",
      "1163/1163 [==============================] - 1s 949us/step - loss: 3.1353 - accuracy: 0.0411\n",
      "Epoch 11/15\n",
      "1163/1163 [==============================] - 1s 1ms/step - loss: 4.6239 - accuracy: 0.0438\n",
      "Epoch 12/15\n",
      "1163/1163 [==============================] - 1s 948us/step - loss: 3.1369 - accuracy: 0.0399\n",
      "Epoch 13/15\n",
      "1163/1163 [==============================] - 1s 1ms/step - loss: 3.1388 - accuracy: 0.0403\n",
      "Epoch 14/15\n",
      "1163/1163 [==============================] - 1s 949us/step - loss: 3.1390 - accuracy: 0.0395\n",
      "Epoch 15/15\n",
      "1163/1163 [==============================] - 1s 1ms/step - loss: 3.1394 - accuracy: 0.0392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faadbc0a8b0>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size = 30, epochs=15, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bef0f",
   "metadata": {},
   "source": [
    "# Test trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d7fc6dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(0, 2), dtype=float32, numpy=array([], shape=(0, 2), dtype=float32)>"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(x_train[100:5])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "dd72de66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[6.1063015e-17, 1.0000000e+00],\n",
       "       [6.1063015e-17, 1.0000000e+00],\n",
       "       [6.1063015e-17, 1.0000000e+00],\n",
       "       [6.1063015e-17, 1.0000000e+00],\n",
       "       [6.1063022e-17, 1.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model(x_train[-5:])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82600361",
   "metadata": {},
   "source": [
    "add softmax to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "3ab8363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "15ece012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.30158493, 0.6984151 ],\n",
       "       [0.30158493, 0.6984151 ],\n",
       "       [0.30158493, 0.6984151 ],\n",
       "       [0.30158493, 0.6984151 ],\n",
       "       [0.30158493, 0.6984151 ]], dtype=float32)>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = probability_model(x_train[-5:])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "9563543c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "24785e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 2), dtype=float32, numpy=\n",
       "array([[0.49616787, 0.5038321 ],\n",
       "       [0.49616787, 0.5038321 ],\n",
       "       [0.49616787, 0.5038321 ],\n",
       "       [0.49616787, 0.5038321 ],\n",
       "       [0.4961679 , 0.5038321 ]], dtype=float32)>"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = probability_model(x_train[:5])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "79cc4307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107ff219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b0084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
