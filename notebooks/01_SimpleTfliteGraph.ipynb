{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f786eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54cb293",
   "metadata": {},
   "source": [
    "# model with single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6e3a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = layers.Input(shape=(3, 4, 6))\n",
    "added = layers.Add()([input1, tf.ones_like(input1)])\n",
    "model = keras.models.Model(inputs=input1, outputs=added)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27293de3",
   "metadata": {},
   "source": [
    "### show inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c329c6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 4, 6), dtype=float32, numpy=\n",
       "array([[[[2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.]],\n",
       "\n",
       "        [[2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.],\n",
       "         [2., 2., 2., 2., 2., 2.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(tf.ones((1, 3, 4, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0b96d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [4., 5.],\n",
       "       [6., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(np.array([[1,2], [3,4], [5,6]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9800a55",
   "metadata": {},
   "source": [
    "## save tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b14f32e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4m1v3r_y/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garbade/.pyenv/versions/3.8.5/envs/py38_venv/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp4m1v3r_y/assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed2a1c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"adder_model_single_input_3x4x6.tflite\", \"wb\") as file:\n",
    "    file.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e1de6",
   "metadata": {},
   "source": [
    "## Example inference using tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b43be07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input details:\n",
      "[{'name': 'input_7', 'index': 0, 'shape': array([1, 2, 3], dtype=int32), 'shape_signature': array([-1,  2,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n",
      "Output details:\n",
      "[{'name': 'Identity', 'index': 4, 'shape': array([1, 2, 3], dtype=int32), 'shape_signature': array([-1,  2,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "\n",
      "Inference output: [[[1. 2. 3.]\n",
      "  [4. 5. 6.]]]\n"
     ]
    }
   ],
   "source": [
    "# TFLite quantized inference example\n",
    "#\n",
    "# Based on:\n",
    "# https://www.tensorflow.org/lite/performance/post_training_integer_quant\n",
    "# https://www.tensorflow.org/lite/api_docs/java/org/tensorflow/lite/Tensor.QuantizationParams\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Location of tflite model file (float32 or int8 quantized)\n",
    "# model_path = \"adder_model_single_input.tflite\"\n",
    "model_path = \"adder_model_single_input_2x3.tflite\"\n",
    "# model_path = \"signn_static.tflite\"\n",
    "\n",
    "# Processed features (copy from Edge Impulse project)\n",
    "# features = [1.0, 2.0]\n",
    "x = np.arange(6)\n",
    "features = x.reshape((2, 3))\n",
    "  \n",
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Allocate tensors\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Print the input and output details of the model\n",
    "print()\n",
    "print(\"Input details:\")\n",
    "print(input_details)\n",
    "print()\n",
    "print(\"Output details:\")\n",
    "print(output_details)\n",
    "print()\n",
    "\n",
    "# Convert features to NumPy array\n",
    "np_features = np.array(features)\n",
    "\n",
    "# If the expected input type is int8 (quantized model), rescale data\n",
    "input_type = input_details[0]['dtype']\n",
    "    \n",
    "# Convert features to NumPy array of expected type\n",
    "np_features = np_features.astype(input_type)\n",
    "\n",
    "# Add dimension to input sample (TFLite model expects (# samples, data))\n",
    "np_features = np.expand_dims(np_features, axis=0)\n",
    "\n",
    "# Create input tensor out of raw features\n",
    "interpreter.set_tensor(input_details[0]['index'], np_features)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# output_details[0]['index'] = the index which provides the input\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# If the output type is int8 (quantized model), rescale data\n",
    "output_type = output_details[0]['dtype']\n",
    "\n",
    "# Print the results of inference\n",
    "print(\"Inference output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6f589fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "01153918",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "functions = []\n",
    "for i in range(10):\n",
    "    functions.append(lambda i: i)\n",
    "\n",
    "for i, f in enumerate(functions):\n",
    "    print(f(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea265e30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
